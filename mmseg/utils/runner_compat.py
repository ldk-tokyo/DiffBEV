# Copyright (c) OpenMMLab. All rights reserved.
"""
MMCV 1.x Runner å…¼å®¹ç±»ï¼šæä¾›ä¸MMCV 1.x Runnerå…¼å®¹çš„æ¥å£
"""
import warnings
import os
import time
import torch
from collections import OrderedDict

# FP16æ”¯æŒï¼ˆä¼˜å…ˆä½¿ç”¨æ–°çš„torch.amp APIï¼‰
try:
    from torch.amp import GradScaler, autocast
    AMP_AVAILABLE = True
    AMP_NEW_API = True
except ImportError:
    try:
        from torch.cuda.amp import GradScaler, autocast
        AMP_AVAILABLE = True
        AMP_NEW_API = False
    except ImportError:
        AMP_AVAILABLE = False
        AMP_NEW_API = False
        autocast = None
        GradScaler = None


class MMCVRunnerCompat(object):
    """å…¼å®¹MMCV 1.x Runneræ¥å£çš„åŒ…è£…ç±»
    
    è¿™ä¸ªç±»å®ç°äº†MMCV 1.x Runnerçš„åŸºæœ¬æ¥å£ï¼Œä»¥æ”¯æŒç°æœ‰çš„è®­ç»ƒæµç¨‹ã€‚
    æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼ŒæŸäº›é«˜çº§åŠŸèƒ½å¯èƒ½ä¸æ”¯æŒã€‚
    """
    
    def __init__(self,
                 model=None,
                 optimizer=None,
                 work_dir=None,
                 logger=None,
                 meta=None,
                 batch_processor=None,
                 runner_type='IterBasedRunner',
                 max_iters=None,
                 max_epochs=None):
        """åˆå§‹åŒ–Runner
        
        Args:
            model: æ¨¡å‹
            optimizer: ä¼˜åŒ–å™¨
            work_dir: å·¥ä½œç›®å½•
            logger: æ—¥å¿—è®°å½•å™¨
            meta: å…ƒæ•°æ®
            batch_processor: æ‰¹å¤„ç†å™¨ï¼ˆå·²åºŸå¼ƒï¼‰
            runner_type: Runnerç±»å‹ ('IterBasedRunner' æˆ– 'EpochBasedRunner')
            max_iters: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆIterBasedRunnerï¼‰
            max_epochs: æœ€å¤§epochæ•°ï¼ˆEpochBasedRunnerï¼‰
        """
        self.model = model
        self.optimizer = optimizer
        self.work_dir = work_dir
        self.logger = logger
        self.meta = meta or {}
        self.batch_processor = batch_processor
        self.runner_type = runner_type
        self.max_iters = max_iters
        self.max_epochs = max_epochs
        
        # RunnerçŠ¶æ€
        self.iter = 0
        self.epoch = 0
        self.inner_iter = 0
        self.mode = 'train'
        self.timestamp = None
        
        # Hookså­˜å‚¨
        self.hooks = []
        self.hook_priority_map = {
            'LOWEST': 0,
            'LOW': 10,
            'NORMAL': 50,
            'HIGH': 90,
            'HIGHEST': 100
        }
        
        # åˆå§‹åŒ–iter/epoch
        if runner_type == 'IterBasedRunner':
            self.by_epoch = False
        else:
            self.by_epoch = True
        
        # metrics_loggerå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åˆå§‹åŒ–
        self.metrics_logger = None
        
        # ä¿å­˜ç¬¬ä¸€æ¬¡è¿­ä»£çš„è¾“å‡ºç”¨äºlossç»“æ„æ£€æŸ¥
        self._first_iter_outputs = None
        
        # FP16/BF16æ”¯æŒï¼ˆå°†åœ¨é…ç½®æ—¶åˆå§‹åŒ–ï¼‰
        self.fp16_enabled = False
        self.bf16_enabled = False
        self.fp16_scaler = None
        self.amp_dtype = None  # 'float16' æˆ– 'bfloat16'
        
        # æ¢¯åº¦è£å‰ªé…ç½®ï¼ˆå°†åœ¨register_training_hooksæ—¶è®¾ç½®ï¼‰
        self.grad_clip = None
    
    def register_training_hooks(self,
                                lr_config=None,
                                optimizer_config=None,
                                checkpoint_config=None,
                                log_config=None,
                                momentum_config=None,
                                timer_config=dict(type='IterTimerHook')):
        """æ³¨å†Œè®­ç»ƒhooksï¼ˆå…¼å®¹MMCV 1.xæ¥å£ï¼‰
        
        Args:
            lr_config: å­¦ä¹ ç‡é…ç½®
            optimizer_config: ä¼˜åŒ–å™¨é…ç½®
            checkpoint_config: checkpointé…ç½®
            log_config: æ—¥å¿—é…ç½®
            momentum_config: momentumé…ç½®
            timer_config: timeré…ç½®
        """
        warnings.warn(
            "register_training_hooks ä½¿ç”¨å…¼å®¹å®ç°ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å®Œæ•´ã€‚"
            "å»ºè®®æ£€æŸ¥è®­ç»ƒæµç¨‹æ˜¯å¦æ­£å¸¸ã€‚"
        )
        
        # è¿™é‡Œéœ€è¦æ³¨å†Œå„ç§hooksï¼Œä½†ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶åªæ˜¯ä¿å­˜é…ç½®
        # å®é™…è®­ç»ƒæ—¶ä¼šåœ¨runæ–¹æ³•ä¸­ä½¿ç”¨è¿™äº›é…ç½®
        self.lr_config = lr_config
        self.optimizer_config = optimizer_config
        self.checkpoint_config = checkpoint_config
        self.log_config = log_config
        self.momentum_config = momentum_config
        self.timer_config = timer_config
        
        # ä»optimizer_configä¸­æå–grad_clipé…ç½®
        if optimizer_config is not None and isinstance(optimizer_config, dict):
            self.grad_clip = optimizer_config.get('grad_clip', None)
            if self.grad_clip is not None and self.logger is not None:
                self.logger.info(f"âœ… æ¢¯åº¦è£å‰ªå·²å¯ç”¨: {self.grad_clip}")
        
        # TODO: å®ç°å®é™…çš„hookæ³¨å†Œé€»è¾‘
    
    def register_hook(self, hook, priority='NORMAL'):
        """æ³¨å†Œhook
        
        Args:
            hook: Hookå®ä¾‹
            priority: Hookä¼˜å…ˆçº§ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–æ•´æ•°ï¼‰
        """
        # ç¡®å®šè¦ä½¿ç”¨çš„ä¼˜å…ˆçº§å€¼
        if hasattr(hook, 'priority'):
            # Hookå·²ç»æœ‰priorityå±æ€§ï¼Œç¡®ä¿å®ƒæ˜¯æ•´æ•°ç±»å‹
            hook_priority = hook.priority
            if isinstance(hook_priority, str):
                hook.priority = self.hook_priority_map.get(hook_priority, 50)
            elif not isinstance(hook_priority, int):
                # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ä¹Ÿä¸æ˜¯æ•´æ•°ï¼Œå°è¯•è½¬æ¢æˆ–ä½¿ç”¨é»˜è®¤å€¼
                try:
                    hook.priority = int(hook_priority)
                except (ValueError, TypeError):
                    hook.priority = 50
        else:
            # Hookæ²¡æœ‰priorityå±æ€§ï¼Œä½¿ç”¨ä¼ å…¥çš„priorityå‚æ•°
            if isinstance(priority, str):
                hook.priority = self.hook_priority_map.get(priority, 50)
            else:
                hook.priority = int(priority) if priority is not None else 50
        
        self.hooks.append(hook)
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆç¡®ä¿æ‰€æœ‰priorityéƒ½æ˜¯æ•´æ•°ï¼‰
        def get_priority_value(h):
            """è·å–hookçš„ä¼˜å…ˆçº§æ•°å€¼"""
            if not hasattr(h, 'priority'):
                return 50
            p = h.priority
            if isinstance(p, int):
                return p
            elif isinstance(p, str):
                return self.hook_priority_map.get(p, 50)
            else:
                try:
                    return int(p)
                except (ValueError, TypeError):
                    return 50
        
        self.hooks.sort(key=get_priority_value, reverse=True)
    
    def run(self, data_loaders, workflow, max_iters=None, **kwargs):
        """è¿è¡Œè®­ç»ƒï¼ˆå…¼å®¹MMCV 1.xæ¥å£ï¼‰
        
        Args:
            data_loaders: æ•°æ®åŠ è½½å™¨åˆ—è¡¨
            workflow: å·¥ä½œæµç¨‹ï¼Œå¦‚ [('train', 1)]
            max_iters: æœ€å¤§è¿­ä»£æ¬¡æ•°
            **kwargs: å…¶ä»–å‚æ•°
        """
        warnings.warn(
            "run æ–¹æ³•ä½¿ç”¨å…¼å®¹å®ç°ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å®Œæ•´ã€‚"
            "å»ºè®®æ£€æŸ¥è®­ç»ƒæµç¨‹æ˜¯å¦æ­£å¸¸ã€‚"
        )
        
        # è®¾ç½®æœ€å¤§è¿­ä»£æ¬¡æ•°
        if max_iters is None:
            max_iters = self.max_iters or float('inf')
        
        # åˆå§‹åŒ–hooks
        self._call_hook('before_train')
        
        # éå†workflowä¸­çš„æ¯ä¸ªé˜¶æ®µ
        for mode, epochs in workflow:
            assert mode in ['train', 'val', 'test'], \
                f'runner mode should be train, val or test, but got {mode}'
            
            if mode == 'train':
                self.train(data_loaders[0], max_iters=max_iters)
            elif mode == 'val':
                self.val(data_loaders[1] if len(data_loaders) > 1 else data_loaders[0])
            elif mode == 'test':
                self.test(data_loaders[1] if len(data_loaders) > 1 else data_loaders[0])
        
        self._call_hook('after_train')
    
    def train(self, data_loader, max_iters=None):
        """è®­ç»ƒæ¨¡å¼
        
        Args:
            data_loader: æ•°æ®åŠ è½½å™¨
            max_iters: æœ€å¤§è¿­ä»£æ¬¡æ•°
        """
        self.model.train()
        self.mode = 'train'
        
        if max_iters is None:
            max_iters = self.max_iters or float('inf')
        
        data_loader_iter = iter(data_loader)
        
        # æ·»åŠ è¿›åº¦æ¡å’Œæ—¶é—´è·Ÿè¸ª
        try:
            from tqdm import tqdm
            use_tqdm = True
        except ImportError:
            use_tqdm = False
        
        if use_tqdm:
            initial_iter = self.iter
            remaining_iters = max_iters - initial_iter
            pbar = tqdm(
                initial=initial_iter,
                total=max_iters,
                desc=f"Training",
                unit="iter",
                bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
            )
        
        start_time = time.time()
        
        # è®­ç»ƒå¾ªç¯
        while self.iter < max_iters:
            try:
                data_batch = next(data_loader_iter)
            except StopIteration:
                # æ•°æ®åŠ è½½å™¨ç»“æŸï¼Œé‡æ–°å¼€å§‹
                data_loader_iter = iter(data_loader)
                data_batch = next(data_loader_iter)
                self.epoch += 1
            
            self._call_hook('before_train_iter', self.iter)
            
            # è·å–æ¨¡å‹è®¾å¤‡
            if hasattr(self.model, 'module'):
                model = self.model.module
                device = next(model.parameters()).device
            else:
                model = self.model
                device = next(model.parameters()).device
            
            # è§£åŒ…DataContainerï¼ˆå¦‚æœéœ€è¦ï¼‰å¹¶ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
            # MMDataParallelä¼šè‡ªåŠ¨è§£åŒ…ï¼Œä½†å¦‚æœç›´æ¥è°ƒç”¨æ¨¡å‹ï¼Œéœ€è¦æ‰‹åŠ¨è§£åŒ…
            unwrapped_batch = {}
            for key, value in data_batch.items():
                # æ£€æŸ¥æ˜¯å¦æ˜¯DataContainer
                if hasattr(value, 'data') and hasattr(value, 'stack') and hasattr(value, 'padding_value'):
                    # æ˜¯DataContainerï¼Œè§£åŒ…data
                    data = value.data
                    # æ£€æŸ¥cpu_onlyæ ‡å¿—
                    if not getattr(value, 'cpu_only', False) and isinstance(data, torch.Tensor):
                        # å¦‚æœä¸åœ¨CPUä¸Šï¼Œç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
                        data = data.to(device)
                    unwrapped_batch[key] = data
                elif isinstance(value, torch.Tensor):
                    # å¦‚æœæ˜¯Tensorï¼Œç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
                    unwrapped_batch[key] = value.to(device)
                else:
                    # ä¸æ˜¯DataContainerä¹Ÿä¸æ˜¯Tensorï¼Œç›´æ¥ä½¿ç”¨
                    unwrapped_batch[key] = value
            
            # å¤„ç†img_metasï¼ˆå¯èƒ½æ˜¯DataContaineråˆ—è¡¨ï¼Œé€šå¸¸æ˜¯cpu_onlyï¼‰
            if 'img_metas' in unwrapped_batch:
                img_metas = unwrapped_batch['img_metas']
                if isinstance(img_metas, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°è¯•è§£åŒ…æ¯ä¸ªå…ƒç´ 
                    unwrapped_img_metas = []
                    for meta in img_metas:
                        if hasattr(meta, 'data'):
                            # æ˜¯DataContainerï¼Œé€šå¸¸img_metasæ˜¯cpu_only
                            unwrapped_img_metas.append(meta.data)
                        else:
                            unwrapped_img_metas.append(meta)
                    unwrapped_batch['img_metas'] = unwrapped_img_metas
            
            # æ‰§è¡Œè®­ç»ƒæ­¥éª¤ï¼ˆFP16/BF16æ”¯æŒï¼šä½¿ç”¨autocaståŒ…è£…forward passï¼‰
            if (self.fp16_enabled or self.bf16_enabled) and AMP_AVAILABLE:
                if AMP_NEW_API:
                    # æ ¹æ®é…ç½®é€‰æ‹©dtype
                    if self.bf16_enabled:
                        # BF16: ä½¿ç”¨bfloat16ï¼Œæ•°å€¼èŒƒå›´ä¸FP32ç›¸åŒï¼Œæ›´ç¨³å®š
                        with autocast(device_type='cuda', dtype=torch.bfloat16):
                            outputs = model.train_step(unwrapped_batch, self.optimizer)
                    else:
                        # FP16: é»˜è®¤ä½¿ç”¨float16
                        with autocast(device_type='cuda', dtype=torch.float16):
                            outputs = model.train_step(unwrapped_batch, self.optimizer)
                else:
                    # æ—§APIï¼šFP16ä½¿ç”¨é»˜è®¤autocastï¼ŒBF16éœ€è¦æŒ‡å®šdtype
                    if self.bf16_enabled:
                        with autocast(dtype=torch.bfloat16):
                            outputs = model.train_step(unwrapped_batch, self.optimizer)
                    else:
                        with autocast():
                            outputs = model.train_step(unwrapped_batch, self.optimizer)
            else:
                outputs = model.train_step(unwrapped_batch, self.optimizer)
            
            # æ‰§è¡Œhooksï¼ˆå¦‚ä¼˜åŒ–å™¨stepã€å­¦ä¹ ç‡æ›´æ–°ç­‰ï¼‰
            if not isinstance(outputs, dict):
                raise TypeError('model.train_step() must return a dict')
            
            # åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶ï¼ˆiter=0ï¼Œå®é™…æ˜¯ç¬¬1æ¬¡è¿­ä»£ï¼‰ï¼Œä¿å­˜outputsç”¨äºlossç»“æ„æ£€æŸ¥
            if self.iter == 0:
                self._first_iter_outputs = outputs.copy() if isinstance(outputs, dict) else {}
            
            if 'log_vars' in outputs:
                # log_bufferæ˜¯OrderedDictï¼Œupdate()åªæ¥å—ä¸€ä¸ªå‚æ•°
                self.log_buffer.update(outputs['log_vars'])
            
            # åå‘ä¼ æ’­å’Œä¼˜åŒ–å™¨æ›´æ–°
            if 'loss' in outputs:
                loss_tensor = outputs['loss']
                
                # æ£€æŸ¥lossæ˜¯å¦ä¸ºnanæˆ–0ï¼ˆåœ¨åå‘ä¼ æ’­å‰ï¼‰
                if isinstance(loss_tensor, torch.Tensor):
                    if torch.isnan(loss_tensor).any():
                        raise RuntimeError(
                            f"âŒ è®­ç»ƒç»ˆæ­¢: Iter {self.iter+1} æ—¶æ£€æµ‹åˆ°æ€»lossä¸º NaNï¼"
                        )
                    if loss_tensor.item() == 0.0:
                        raise RuntimeError(
                            f"âŒ è®­ç»ƒç»ˆæ­¢: Iter {self.iter+1} æ—¶æ£€æµ‹åˆ°æ€»lossä¸º 0ï¼"
                        )
                    
                    # æ£€æŸ¥lossæ˜¯å¦å‚ä¸è®¡ç®—å›¾ï¼ˆrequires_gradï¼‰
                    if not loss_tensor.requires_grad:
                        raise RuntimeError(
                            f"âŒ è®­ç»ƒç»ˆæ­¢: Iter {self.iter+1} æ—¶æ£€æµ‹åˆ°lossæœªå‚ä¸åå‘ä¼ æ’­ï¼"
                            f"loss.requires_grad = {loss_tensor.requires_grad}ã€‚"
                            f"è¯·æ£€æŸ¥lossè®¡ç®—æ˜¯å¦æ­£ç¡®ã€‚"
                        )
                
                self.optimizer.zero_grad()
                
                # FP16/BF16æ”¯æŒï¼šä½¿ç”¨GradScalerè¿›è¡Œåå‘ä¼ æ’­ï¼ˆä»…FP16éœ€è¦scalerï¼‰
                if self.fp16_enabled and self.fp16_scaler is not None:
                    self.fp16_scaler.scale(loss_tensor).backward()
                    
                    # FP16: æ£€æŸ¥scalerçŠ¶æ€ï¼Œå¦‚æœå‡ºç°inf/NaNï¼Œè·³è¿‡æ­¤æ¬¡æ›´æ–°
                    scaler_state = self.fp16_scaler.get_scale()
                    if scaler_state == float('inf') or scaler_state != scaler_state:  # NaNæ£€æŸ¥
                        self.logger.warning(
                            f"âš ï¸  Iter {self.iter+1}: FP16 scaleræ£€æµ‹åˆ°inf/NaNï¼Œè·³è¿‡æ­¤æ¬¡æ›´æ–°å¹¶é™ä½loss_scale"
                        )
                        # scalerä¼šè‡ªåŠ¨å¤„ç†ï¼Œè¿™é‡Œåªè®°å½•è­¦å‘Š
                    
                    # FP16: unscaleæ¢¯åº¦ä»¥æ£€æŸ¥NaNï¼ˆåœ¨stepä¹‹å‰ï¼‰
                    self.fp16_scaler.unscale_(self.optimizer)
                    
                    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦å­˜åœ¨å’Œæ˜¯å¦ä¸ºNaNï¼ˆåœ¨unscaleä¹‹åï¼‰
                    has_grad = False
                    has_nan = False
                    nan_param_name = None
                    for name, param in model.named_parameters():
                        if param.grad is not None:
                            has_grad = True
                            if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():
                                has_nan = True
                                nan_param_name = name
                                break
                    
                    if not has_grad:
                        warnings.warn(
                            f"âš ï¸  Iter {self.iter+1}: æœªæ£€æµ‹åˆ°ä»»ä½•å‚æ•°çš„æ¢¯åº¦ã€‚"
                            f"è¿™å¯èƒ½è¡¨ç¤ºlossæœªæ­£ç¡®è¿æ¥åˆ°æ¨¡å‹å‚æ•°ã€‚"
                        )
                    
                    if has_nan:
                        # FP16: å¦‚æœæ£€æµ‹åˆ°NaNï¼Œè·³è¿‡æ­¤æ¬¡æ›´æ–°
                        self.fp16_scaler.update()  # è¿™ä¼šé™ä½loss_scale
                        self.logger.warning(
                            f"âš ï¸  Iter {self.iter+1}: æ£€æµ‹åˆ°å‚æ•° '{nan_param_name}' çš„æ¢¯åº¦ä¸º NaN/infï¼Œ"
                            f"è·³è¿‡æ­¤æ¬¡æ›´æ–°ã€‚å½“å‰loss_scale: {self.fp16_scaler.get_scale():.2f}"
                        )
                        # è·³è¿‡optimizer.step()
                    else:
                        # æ¢¯åº¦è£å‰ªï¼ˆå¯é€‰ï¼Œä½†å»ºè®®å¯ç”¨ï¼‰
                        if hasattr(self, 'grad_clip') and self.grad_clip is not None:
                            torch.nn.utils.clip_grad_norm_(model.parameters(), **self.grad_clip)
                        
                        # FP16: æ­£å¸¸æ›´æ–°
                        self.fp16_scaler.step(self.optimizer)
                        self.fp16_scaler.update()
                elif self.bf16_enabled:
                    # BF16æ¨¡å¼ï¼šç›´æ¥åå‘ä¼ æ’­ï¼ˆBF16ä¸éœ€è¦GradScalerï¼Œæ•°å€¼èŒƒå›´ä¸FP32ç›¸åŒï¼‰
                    loss_tensor.backward()
                    
                    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦å­˜åœ¨
                    has_grad = False
                    has_nan = False
                    nan_param_name = ""
                    for name, param in model.named_parameters():
                        if param.grad is not None:
                            if param.grad.numel() > 0:  # ç¡®ä¿æ¢¯åº¦å¼ é‡éç©º
                                has_grad = True
                                if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():
                                    has_nan = True
                                    nan_param_name = name
                                    break
                    
                    if not has_grad:
                        warnings.warn(
                            f"âš ï¸  Iter {self.iter+1}: æœªæ£€æµ‹åˆ°ä»»ä½•å‚æ•°çš„æ¢¯åº¦ã€‚"
                            f"è¿™å¯èƒ½è¡¨ç¤ºlossæœªæ­£ç¡®è¿æ¥åˆ°æ¨¡å‹å‚æ•°ã€‚"
                        )
                    
                    if has_nan:
                        warnings.warn(
                            f"âš ï¸  Iter {self.iter+1}: æ£€æµ‹åˆ°å‚æ•° '{nan_param_name}' çš„æ¢¯åº¦ä¸º NaN/infï¼Œè·³è¿‡æ­¤æ¬¡æ›´æ–°ã€‚"
                        )
                    else:
                        # æ¢¯åº¦è£å‰ªï¼ˆå¯é€‰ï¼Œä½†å»ºè®®å¯ç”¨ï¼‰
                        if hasattr(self, 'grad_clip') and self.grad_clip is not None:
                            torch.nn.utils.clip_grad_norm_(model.parameters(), **self.grad_clip)
                        
                        # BF16: ç›´æ¥æ›´æ–°ä¼˜åŒ–å™¨ï¼ˆä¸éœ€è¦scalerï¼‰
                        self.optimizer.step()
                else:
                    # FP32æ¨¡å¼ï¼šç›´æ¥åå‘ä¼ æ’­
                    loss_tensor.backward()
                    
                    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦å­˜åœ¨
                    has_grad = False
                    for param in model.parameters():
                        if param.grad is not None:
                            if torch.isnan(param.grad).any():
                                param_name = next((name for name, p in model.named_parameters() if p is param), "unknown")
                                raise RuntimeError(
                                    f"âŒ è®­ç»ƒç»ˆæ­¢: Iter {self.iter+1} æ—¶æ£€æµ‹åˆ°å‚æ•° '{param_name}' çš„æ¢¯åº¦ä¸º NaNï¼"
                                )
                            has_grad = True
                            break
                    
                    if not has_grad:
                        warnings.warn(
                            f"âš ï¸  Iter {self.iter+1}: æœªæ£€æµ‹åˆ°ä»»ä½•å‚æ•°çš„æ¢¯åº¦ã€‚"
                            f"è¿™å¯èƒ½è¡¨ç¤ºlossæœªæ­£ç¡®è¿æ¥åˆ°æ¨¡å‹å‚æ•°ã€‚"
                        )
                    
                    # æ¢¯åº¦è£å‰ªï¼ˆFP32æ¨¡å¼ï¼‰
                    if hasattr(self, 'grad_clip') and self.grad_clip is not None:
                        torch.nn.utils.clip_grad_norm_(model.parameters(), **self.grad_clip)
                    
                    self.optimizer.step()
            
            # å®šæœŸè®°å½•è®­ç»ƒæŒ‡æ ‡åˆ°æ—¥å¿—ï¼ˆæ¯50æ¬¡è¿­ä»£ï¼‰
            # æ³¨æ„ï¼šå¿…é¡»åœ¨iteré€’å¢ä¹‹å‰æ£€æŸ¥ï¼Œå¦åˆ™ä¼šé”™è¿‡è®°å½•ï¼ˆå¦‚20050å˜æˆ20051åä¸æ»¡è¶³æ¡ä»¶ï¼‰
            log_interval = getattr(self, 'log_interval', 50)
            current_iter = self.iter  # ä¿å­˜å½“å‰iterå€¼ç”¨äºè®°å½•
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è®°å½•ï¼ˆä½¿ç”¨å½“å‰iterï¼Œè€Œä¸æ˜¯é€’å¢åçš„iterï¼‰
            if (current_iter + 1) % log_interval == 0 and hasattr(self, 'logger'):
                log_msg_parts = [f"iter={current_iter + 1}"]
                if 'log_vars' in outputs:
                    for key, value in outputs['log_vars'].items():
                        if isinstance(value, torch.Tensor):
                            value = value.item()
                        if isinstance(value, (int, float)):
                            log_msg_parts.append(f"{key}={value:.6f}")
                        else:
                            log_msg_parts.append(f"{key}={value}")
                if hasattr(self.logger, 'info'):
                    self.logger.info(" | ".join(log_msg_parts))
                
                # ä½¿ç”¨metrics_loggerè®°å½•è®­ç»ƒæŒ‡æ ‡åˆ°TensorBoardå’ŒCSV
                # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨current_iter+1ä½œä¸ºstepï¼Œå› ä¸ºè¿™æ˜¯å½“å‰è¿­ä»£å®Œæˆåçš„iterå€¼
                self._log_training_metrics_to_tb_and_csv(outputs, iter_to_log=current_iter + 1)
            
            # after_train_iter hookåªæ¥å—runnerå‚æ•°ï¼Œä¸ä¼ é€’é¢å¤–çš„iterå‚æ•°
            self._call_hook('after_train_iter')
            
            # ä¿å­˜checkpointï¼ˆæ ¹æ®checkpoint_configï¼‰
            self._save_checkpoint_if_needed()
            
            self.iter += 1
            self.inner_iter += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            if use_tqdm:
                # è·å–å½“å‰æŸå¤±å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
                loss_info = ""
                if 'log_vars' in outputs and 'loss' in outputs['log_vars']:
                    loss_val = outputs['log_vars'].get('loss', 0)
                    if isinstance(loss_val, torch.Tensor):
                        loss_val = loss_val.item()
                    loss_info = f" loss={loss_val:.4f}"
                
                # æå–å…¶ä»–lossåˆ†é‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if 'log_vars' in outputs:
                    if 'loss_seg' in outputs['log_vars']:
                        seg_val = outputs['log_vars']['loss_seg']
                        if isinstance(seg_val, torch.Tensor):
                            seg_val = seg_val.item()
                        loss_info += f" seg={seg_val:.4f}"
                    if 'loss_depth' in outputs['log_vars']:
                        depth_val = outputs['log_vars']['loss_depth']
                        if isinstance(depth_val, torch.Tensor):
                            depth_val = depth_val.item()
                        loss_info += f" depth={depth_val:.4f}"
                    # æå–å­¦ä¹ ç‡
                    if 'learning_rate' in outputs['log_vars']:
                        lr_val = outputs['log_vars']['learning_rate']
                        if isinstance(lr_val, torch.Tensor):
                            lr_val = lr_val.item()
                        loss_info += f" lr={lr_val:.6f}"
                    elif hasattr(self, 'optimizer') and hasattr(self.optimizer, 'param_groups'):
                        lr_val = self.optimizer.param_groups[0].get('lr', 0)
                        if lr_val > 0:
                            loss_info += f" lr={lr_val:.6f}"
                
                # è®¡ç®—å¹³å‡é€Ÿåº¦
                current_time = time.time()
                elapsed_time = current_time - start_time
                if self.iter > initial_iter:
                    avg_time_per_iter = elapsed_time / (self.iter - initial_iter)
                    remaining_iters = max_iters - self.iter
                    eta_seconds = remaining_iters * avg_time_per_iter
                    eta_str = f"ETA={eta_seconds/3600:.1f}h" if eta_seconds > 3600 else f"ETA={eta_seconds/60:.1f}m"
                else:
                    eta_str = "ETA=è®¡ç®—ä¸­..."
                
                # æ›´æ–°è¿›åº¦æ¡æè¿°
                pbar.set_description(f"Training{loss_info} {eta_str}")
                pbar.update(1)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
            if self.iter >= max_iters:
                break
        
        # å…³é—­è¿›åº¦æ¡
        if use_tqdm:
            total_time = time.time() - start_time
            pbar.set_description(f"Trainingå®Œæˆ - æ€»è€—æ—¶: {total_time/3600:.2f}å°æ—¶")
            pbar.close()
    
    def val(self, data_loader):
        """éªŒè¯æ¨¡å¼
        
        Args:
            data_loader: æ•°æ®åŠ è½½å™¨
        """
        self.model.eval()
        self.mode = 'val'
        
        self._call_hook('before_val')
        
        # éªŒè¯å¾ªç¯
        for i, data_batch in enumerate(data_loader):
            self._call_hook('before_val_iter')
            
            with torch.no_grad():
                outputs = self.model.val_step(data_batch, None)
            
            self._call_hook('after_val_iter')
        
        self._call_hook('after_val')
    
    def test(self, data_loader):
        """æµ‹è¯•æ¨¡å¼
        
        Args:
            data_loader: æ•°æ®åŠ è½½å™¨
        """
        self.model.eval()
        self.mode = 'test'
        
        self._call_hook('before_test')
        
        # æµ‹è¯•å¾ªç¯
        for i, data_batch in enumerate(data_loader):
            self._call_hook('before_test_iter')
            
            with torch.no_grad():
                outputs = self.model.test_step(data_batch, None)
            
            self._call_hook('after_test_iter')
        
        self._call_hook('after_test')
    
    def _call_hook(self, fn_name, *args, **kwargs):
        """è°ƒç”¨hooks
        
        Args:
            fn_name: hookå‡½æ•°åï¼Œå¦‚ 'before_train', 'after_train_iter' ç­‰
            *args: ä¼ é€’ç»™hookçš„ä½ç½®å‚æ•°
            **kwargs: ä¼ é€’ç»™hookçš„å…³é”®å­—å‚æ•°
        """
        import inspect
        for hook in self.hooks:
            if hasattr(hook, fn_name):
                hook_fn = getattr(hook, fn_name)
                # æ£€æŸ¥hookå‡½æ•°çš„ç­¾å
                try:
                    sig = inspect.signature(hook_fn)
                    # è·å–å‚æ•°åˆ—è¡¨
                    params = list(sig.parameters.keys())
                    # å¦‚æœhookå‡½æ•°åªéœ€è¦runnerå‚æ•°ï¼Œåªä¼ é€’self
                    if len(params) == 1:
                        hook_fn(self)
                    else:
                        # å¦‚æœhookå‡½æ•°éœ€è¦æ›´å¤šå‚æ•°ï¼Œä¼ é€’selfå’Œargs
                        hook_fn(self, *args, **kwargs)
                except (ValueError, TypeError):
                    # å¦‚æœæ— æ³•è·å–ç­¾åï¼Œå°è¯•ç›´æ¥è°ƒç”¨
                    try:
                        hook_fn(self, *args, **kwargs)
                    except TypeError:
                        # å¦‚æœè°ƒç”¨å¤±è´¥ï¼Œå°è¯•åªä¼ é€’self
                        hook_fn(self)
    
    @property
    def log_buffer(self):
        """æ—¥å¿—ç¼“å†²åŒº"""
        if not hasattr(self, '_log_buffer'):
            self._log_buffer = OrderedDict()
        return self._log_buffer
    
    def _log_training_metrics_to_tb_and_csv(self, outputs, iter_to_log=None):
        """è®°å½•è®­ç»ƒæŒ‡æ ‡åˆ°TensorBoardå’ŒCSV
        
        Args:
            outputs: è®­ç»ƒè¿­ä»£çš„è¾“å‡º
            iter_to_log: è¦è®°å½•çš„iterå€¼ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨self.iterï¼‰
        
        Args:
            outputs: train_stepçš„è¾“å‡ºï¼ŒåŒ…å«log_vars
        """
        try:
            from mmseg.utils.metrics_logger import MetricsLogger
            
            # åˆå§‹åŒ–metrics_loggerï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
            if self.metrics_logger is None:
                self.metrics_logger = MetricsLogger(
                    work_dir=self.work_dir,
                    csv_filename='metrics.csv',
                    mode='train'
                )
            
            if 'log_vars' not in outputs:
                return
            
            log_vars = outputs['log_vars']
            
            # æå–è®­ç»ƒæŸå¤±æŒ‡æ ‡
            Lwce = None
            Ldepth = None
            Ldiff = None
            loss_total = None
            learning_rate = None
            
            # å°è¯•ä»log_varsä¸­æå–å„ç§æŸå¤±
            # Lwceå¯èƒ½åœ¨loss_segæˆ–å…¶ä»–é”®ä¸­
            if 'loss_seg' in log_vars:
                Lwce = log_vars['loss_seg']
                if isinstance(Lwce, torch.Tensor):
                    Lwce = Lwce.item()
            elif 'loss_decode.loss_seg' in log_vars:
                Lwce = log_vars['loss_decode.loss_seg']
                if isinstance(Lwce, torch.Tensor):
                    Lwce = Lwce.item()
            
            # Ldepth
            if 'loss_depth' in log_vars:
                Ldepth = log_vars['loss_depth']
                if isinstance(Ldepth, torch.Tensor):
                    Ldepth = Ldepth.item()
            
            # Ldiff
            if 'loss_diff' in log_vars:
                Ldiff = log_vars['loss_diff']
                if isinstance(Ldiff, torch.Tensor):
                    Ldiff = Ldiff.item()
            elif 'loss_diffusion' in log_vars:
                Ldiff = log_vars['loss_diffusion']
                if isinstance(Ldiff, torch.Tensor):
                    Ldiff = Ldiff.item()
            
            # æ€»æŸå¤±
            if 'loss' in log_vars:
                loss_total = log_vars['loss']
                if isinstance(loss_total, torch.Tensor):
                    loss_total = loss_total.item()
            
            # å­¦ä¹ ç‡
            if hasattr(self, 'optimizer') and self.optimizer is not None:
                # å°è¯•ä»ä¼˜åŒ–å™¨ä¸­è·å–å­¦ä¹ ç‡
                if hasattr(self.optimizer, 'param_groups') and len(self.optimizer.param_groups) > 0:
                    learning_rate = self.optimizer.param_groups[0].get('lr', None)
            if learning_rate is None and 'lr' in log_vars:
                learning_rate = log_vars['lr']
                if isinstance(learning_rate, torch.Tensor):
                    learning_rate = learning_rate.item()
            if learning_rate is None and 'learning_rate' in log_vars:
                learning_rate = log_vars['learning_rate']
                if isinstance(learning_rate, torch.Tensor):
                    learning_rate = learning_rate.item()
            
            # è®°å½•åˆ°metrics_logger
            # ä½¿ç”¨iter_to_logï¼ˆå¦‚æœæä¾›ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨self.iter
            step_to_log = iter_to_log if iter_to_log is not None else self.iter
            self.metrics_logger.log_training_losses(
                Lwce=Lwce,
                Ldepth=Ldepth,
                Ldiff=Ldiff,
                loss_total=loss_total,
                learning_rate=learning_rate,
                step=step_to_log,
                prefix='train',
                mode='train'
            )
            
            # åˆ·æ–°ç¼“å†²åŒº
            self.metrics_logger.flush()
            
        except Exception as e:
            # å¦‚æœè®°å½•å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­æ‰§è¡Œ
            if hasattr(self, 'logger'):
                self.logger.warning(f'Failed to log training metrics to TensorBoard/CSV: {e}')
            else:
                print(f'Warning: Failed to log training metrics to TensorBoard/CSV: {e}')
    
    def resume(self, checkpoint):
        """æ¢å¤è®­ç»ƒ
        
        Args:
            checkpoint: checkpointè·¯å¾„
        """
        import os
        import torch
        
        if not os.path.exists(checkpoint):
            raise FileNotFoundError(f"Checkpointæ–‡ä»¶ä¸å­˜åœ¨: {checkpoint}")
        
        if self.logger is not None:
            self.logger.info(f"ğŸ“‚ ä»checkpointæ¢å¤è®­ç»ƒ: {checkpoint}")
        
        # åŠ è½½checkpoint
        checkpoint_data = torch.load(checkpoint, map_location='cpu')
        
        # æ¢å¤è¿­ä»£æ¬¡æ•°å’Œepoch
        if 'iter' in checkpoint_data:
            self.iter = checkpoint_data['iter']
        if 'epoch' in checkpoint_data:
            self.epoch = checkpoint_data['epoch']
        
        # æ¢å¤æ¨¡å‹çŠ¶æ€
        if 'state_dict' in checkpoint_data:
            if hasattr(self.model, 'module'):
                self.model.module.load_state_dict(checkpoint_data['state_dict'])
            else:
                self.model.load_state_dict(checkpoint_data['state_dict'])
        
        # æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€
        if 'optimizer' in checkpoint_data and self.optimizer is not None:
            self.optimizer.load_state_dict(checkpoint_data['optimizer'])
        
        # æ¢å¤FP16 scalerçŠ¶æ€
        if 'fp16_scaler' in checkpoint_data and self.fp16_enabled and self.fp16_scaler is not None:
            self.fp16_scaler.load_state_dict(checkpoint_data['fp16_scaler'])
        
        if self.logger is not None:
            self.logger.info(f"âœ… å·²æ¢å¤è®­ç»ƒçŠ¶æ€: iter={self.iter}, epoch={self.epoch}")
    
    def load_checkpoint(self, filename):
        """åŠ è½½checkpointï¼ˆä»…åŠ è½½æ¨¡å‹æƒé‡ï¼Œä¸æ¢å¤è®­ç»ƒçŠ¶æ€ï¼‰
        
        Args:
            filename: checkpointæ–‡ä»¶è·¯å¾„
        """
        import os
        import torch
        
        if not os.path.exists(filename):
            raise FileNotFoundError(f"Checkpointæ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        
        if self.logger is not None:
            self.logger.info(f"ğŸ“‚ åŠ è½½checkpoint: {filename}")
        
        checkpoint_data = torch.load(filename, map_location='cpu')
        
        # åªåŠ è½½æ¨¡å‹æƒé‡
        if 'state_dict' in checkpoint_data:
            state_dict = checkpoint_data['state_dict']
        else:
            # å¦‚æœæ²¡æœ‰state_dicté”®ï¼Œå‡è®¾æ•´ä¸ªcheckpointå°±æ˜¯state_dict
            state_dict = checkpoint_data
        
        if hasattr(self.model, 'module'):
            self.model.module.load_state_dict(state_dict, strict=False)
        else:
            self.model.load_state_dict(state_dict, strict=False)
        
        if self.logger is not None:
            self.logger.info("âœ… æ¨¡å‹æƒé‡å·²åŠ è½½")
    
    def save_checkpoint(self,
                       out_dir,
                       filename_tmpl='iter_{}.pth',
                       meta=None,
                       create_symlink=True):
        """ä¿å­˜checkpoint
        
        Args:
            out_dir: è¾“å‡ºç›®å½•
            filename_tmpl: æ–‡ä»¶åæ¨¡æ¿
            meta: å…ƒæ•°æ®
            create_symlink: æ˜¯å¦åˆ›å»ºç¬¦å·é“¾æ¥
        """
        import os
        import torch
        
        os.makedirs(out_dir, exist_ok=True)
        
        # å‡†å¤‡checkpointæ•°æ®
        checkpoint = {
            'meta': meta or self.meta.copy(),
            'iter': self.iter,
            'epoch': self.epoch,
        }
        
        # ä¿å­˜æ¨¡å‹çŠ¶æ€
        if hasattr(self.model, 'module'):
            checkpoint['state_dict'] = self.model.module.state_dict()
        else:
            checkpoint['state_dict'] = self.model.state_dict()
        
        # ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€
        if self.optimizer is not None:
            checkpoint['optimizer'] = self.optimizer.state_dict()
        
        # ä¿å­˜FP16 scalerçŠ¶æ€
        if self.fp16_enabled and self.fp16_scaler is not None:
            checkpoint['fp16_scaler'] = self.fp16_scaler.state_dict()
        
        # ç”Ÿæˆæ–‡ä»¶å
        filename = filename_tmpl.format(self.iter)
        filepath = os.path.join(out_dir, filename)
        
        # ä¿å­˜checkpoint
        torch.save(checkpoint, filepath)
        
        if self.logger is not None:
            self.logger.info(f"âœ… Checkpointå·²ä¿å­˜: {filepath}")
        
        # åˆ›å»ºlatest.pthç¬¦å·é“¾æ¥
        if create_symlink:
            latest_path = os.path.join(out_dir, 'latest.pth')
            if os.path.exists(latest_path):
                os.remove(latest_path)
            os.symlink(filename, latest_path)
        
        return filepath
    
    def _save_checkpoint_if_needed(self):
        """æ ¹æ®checkpoint_configæ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜checkpoint"""
        if self.checkpoint_config is None:
            return
        
        # æ£€æŸ¥æ˜¯å¦åˆ°äº†ä¿å­˜é—´éš”
        interval = self.checkpoint_config.get('interval', 5000)
        by_epoch = self.checkpoint_config.get('by_epoch', False)
        
        should_save = False
        if by_epoch:
            # åŸºäºepochä¿å­˜
            if self.epoch > 0 and self.epoch % interval == 0:
                should_save = True
        else:
            # åŸºäºiterationä¿å­˜
            if self.iter > 0 and self.iter % interval == 0:
                should_save = True
        
        if should_save:
            # è·å–max_keep_ckptsé…ç½®
            max_keep_ckpts = self.checkpoint_config.get('max_keep_ckpts', -1)
            
            # ä¿å­˜checkpoint
            self.save_checkpoint(
                out_dir=self.work_dir,
                filename_tmpl='iter_{}.pth',
                create_symlink=True,
                meta=self.meta
            )
            
            # æ¸…ç†æ—§checkpointï¼ˆå¦‚æœè®¾ç½®äº†max_keep_ckptsï¼‰
            if max_keep_ckpts > 0:
                self._cleanup_old_checkpoints(max_keep_ckpts)
    
    def _cleanup_old_checkpoints(self, max_keep):
        """æ¸…ç†æ—§çš„checkpointæ–‡ä»¶ï¼Œåªä¿ç•™æœ€è¿‘çš„max_keepä¸ª"""
        import os
        import glob
        
        # æŸ¥æ‰¾æ‰€æœ‰checkpointæ–‡ä»¶
        pattern = os.path.join(self.work_dir, 'iter_*.pth')
        checkpoint_files = glob.glob(pattern)
        
        # æ’é™¤latest.pthç¬¦å·é“¾æ¥
        checkpoint_files = [f for f in checkpoint_files if not f.endswith('latest.pth')]
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        checkpoint_files.sort(key=os.path.getmtime, reverse=True)
        
        # åˆ é™¤å¤šä½™çš„checkpoint
        if len(checkpoint_files) > max_keep:
            for old_file in checkpoint_files[max_keep:]:
                try:
                    os.remove(old_file)
                    if self.logger is not None:
                        self.logger.info(f"ğŸ—‘ï¸  åˆ é™¤æ—§checkpoint: {os.path.basename(old_file)}")
                except Exception as e:
                    if self.logger is not None:
                        self.logger.warning(f"âš ï¸  æ— æ³•åˆ é™¤æ—§checkpoint {old_file}: {e}")
    
    @property
    def rank(self):
        """å½“å‰è¿›ç¨‹çš„rankï¼ˆåˆ†å¸ƒå¼è®­ç»ƒï¼‰"""
        try:
            import torch.distributed as dist
            if dist.is_initialized():
                return dist.get_rank()
        except:
            pass
        return 0
    
    @property
    def world_size(self):
        """æ€»è¿›ç¨‹æ•°ï¼ˆåˆ†å¸ƒå¼è®­ç»ƒï¼‰"""
        try:
            import torch.distributed as dist
            if dist.is_initialized():
                return dist.get_world_size()
        except:
            pass
        return 1
